import type { SearchResult } from '@/types/chat'

export interface GLMMessage {
  role: 'user' | 'assistant' | 'system' | 'tool'
  content: string
  name?: string
  tool_call_id?: string
}

export interface GLMChatRequest {
  model: string
  messages: GLMMessage[]
  stream?: boolean
  temperature?: number
  max_tokens?: number
}

export interface GLMToolCall {
  id: string
  type: string
  function: {
    name: string
    arguments: string
  }
}

export interface GLMChatResponse {
  id: string
  object: string
  created: number
  model: string
  choices: {
    index: number
    message: {
      role: string
      content: string
    }
    finish_reason: string
  }[]
  usage: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
}

export interface GLMStreamResponse {
  id: string
  object: string
  created: number
  model: string
  choices: {
    index: number
    delta: {
      role?: string
      content?: string
      reasoning_content?: string
      tool_calls?: GLMToolCall[]
    }
    finish_reason?: string
  }[]
}

export interface GLMWebSearchResult {
  title: string
  content: string
  link: string
  media?: string
  icon?: string
  refer?: string
  publish_date?: string
}

export interface GLMWebSearchResponse {
  id: string
  created: number
  request_id: string
  search_intent?: {
    query: string
    intent: 'SEARCH_ALL' | 'SEARCH_NONE' | 'SEARCH_ALWAYS'
    keywords?: string
  }[]
  search_result?: GLMWebSearchResult[]
}

export class GLMService {
  private baseURL = 'https://open.bigmodel.cn/api/paas/v4'
  private apiKey: string

  constructor(apiKey: string) {
    this.apiKey = apiKey
  }

  private needsWebSearch(message: string): boolean {
    const searchKeywords = [
      'ÊúÄÊñ∞',
      'Êñ∞Èóª',
      '‰ªäÂ§©',
      'Êò®Â§©',
      'Áé∞Âú®',
      'ÂÆûÊó∂',
      'ÂΩìÂâç',
      'Â§©Ê∞î',
      'ËÇ°Â∏Ç',
      'ËÇ°Á•®',
      'Ê±áÁéá',
      '‰ª∑Ê†º',
      'Ë°åÊÉÖ',
      'ËµÑËÆØ',
      'ÁÉ≠ÁÇπ',
      'ÊêúÁ¥¢',
      'Êü•ËØ¢',
      'Êâæ‰∏Ä‰∏ã',
      'ÁôæÂ∫¶',
      'Ë∞∑Ê≠å',
      '2024',
      '2025',
      '‰ªäÂπ¥',
      'Êú¨Êúà',
      'Êú¨Âë®',
      'ÊúÄËøë',
    ]

    return searchKeywords.some((keyword) => message.includes(keyword))
  }

  private async performWebSearch(query: string): Promise<GLMWebSearchResponse | null> {
    const trimmedQuery = query.trim()
    if (!trimmedQuery) {
      return null
    }

    const payload = {
      search_query: trimmedQuery.slice(0, 70),
      search_engine: 'search_std',
      search_intent: true,
      count: 8,
      content_size: 'medium',
    }

    // When executed server-side (e.g., in tests) we can callÂ§ßÊ®°ÂûãÊé•Âè£ directly.
    if (typeof window === 'undefined') {
      const response = await fetch(`${this.baseURL}/web_search`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify(payload),
      })

      if (!response.ok) {
        const errorText = await response.text()
        throw new Error(`Web search error: ${response.status} ${errorText}`)
      }

      return response.json()
    }

    const proxyResponse = await fetch('/api/web-search', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        ...payload,
        apiKey: this.apiKey,
      }),
    })

    if (!proxyResponse.ok) {
      const errorText = await proxyResponse.text()
      throw new Error(`Web search proxy error: ${proxyResponse.status} ${errorText}`)
    }

    return proxyResponse.json()
  }

  private formatWebSearchResults(
    response: GLMWebSearchResponse | null
  ): { formattedText: string; structuredResults: SearchResult[] } | null {
    if (!response?.search_result?.length) {
      return null
    }

    const structuredResults: SearchResult[] = response.search_result.slice(0, 5).map((item) => ({
      title: item.title || 'Êú™ÂëΩÂêçÁªìÊûú',
      summary: item.content?.trim() || 'ÔºàÊöÇÊó†ÊëòË¶ÅÔºâ',
      link: item.link,
      source: item.media || item.refer || 'Êú™Áü•Êù•Ê∫ê',
      publishedAt: item.publish_date,
    }))

    const formattedText = structuredResults
      .map((result, index) => {
        const publishedAt = result.publishedAt ? `Ôºà${result.publishedAt}Ôºâ` : ''
        return `${index + 1}. ${result.title}${publishedAt}\nÊù•Ê∫êÔºö${result.source}\nÈìæÊé•Ôºö${result.link}\nÊëòË¶ÅÔºö${result.summary}`
      })
      .join('\n\n')

    return { formattedText, structuredResults }
  }

  private isUsefulSentence(sentence: string): boolean {
    if (!sentence) {
      return false
    }

    const trimmed = sentence.trim()
    if (trimmed.length < 2 || trimmed.length > 120) {
      return false
    }

    const excludedKeywords = [
      'ÂàÜÊûê',
      'Áî®Êà∑',
      'ËØ∑Ê±Ç',
      '‰ªªÂä°',
      'Á∫¶Êùü',
      'ËÄÉËôë',
      'Â∫îËØ•',
      'ÂèØ‰ª•',
      'Ê®°Âºè',
      'ÈÄâÊã©',
      'ÈÄâÈ°π',
      'Ê†∏ÂøÉ',
      'ÂÖ≥ÈîÆ',
      'Ê≠•È™§',
      'ÊñπÊ°à',
      'ÈúÄË¶Å',
    ]

    return !excludedKeywords.some((keyword) => trimmed.includes(keyword))
  }

  private extractReplyFromReasoning(reasoningContent: string): string {
    if (reasoningContent.length < 50) {
      return reasoningContent
    }

    console.log('Â∞ùËØï‰ªé reasoning_content ‰∏≠ÊèêÂèñÂèØËØªÂõûÂ§ç')

    const quotedMatches = reasoningContent.match(/"([^"]{1,120})"/g)
    if (quotedMatches) {
      for (const match of quotedMatches) {
        const content = match.replace(/"/g, '').trim()
        if (this.isUsefulSentence(content)) {
          console.log('ÂëΩ‰∏≠ÂºïÂè∑ÂÜÖÂÆπ:', content)
          return content
        }
      }
    }

    const patterns = [
      /(?:ÊúÄÁªàÂõûÁ≠î|ÊúÄÁªàÂõûÂ§ç|ÊúÄÁªàÈÄâÊã©|ÊúÄ‰Ω≥ÈÄâÈ°π)[Ôºö:]\s*"([^"]+)"/,
      /(?:ÊúÄÁªàÂõûÁ≠î|ÊúÄÁªàÂõûÂ§ç|ÊúÄÁªàÈÄâÊã©|ÊúÄ‰Ω≥ÈÄâÈ°π)[Ôºö:]\s*([^\n]+)/,
      /(?:Âõ†Ê≠§|ÊâÄ‰ª•|Áªº‰∏ä)[Ôºå,Ôºå]\s*"([^"]+)"/,
      /(?:Âõ†Ê≠§|ÊâÄ‰ª•|Áªº‰∏ä)[Ôºå,Ôºå]\s*([^\n]+)/,
    ]

    for (const pattern of patterns) {
      const match = reasoningContent.match(pattern)
      if (match) {
        const content = (match[1] || match[0]).replace(/^[^"]*"/, '').replace(/"$/, '').trim()
        if (this.isUsefulSentence(content)) {
          console.log('ÂëΩ‰∏≠Ê®°ÂºèÂÜÖÂÆπ:', content)
          return content
        }
      }
    }

    const sentences = reasoningContent.split(/[„ÄÇÔºÅÔºü!?\\n]+/)
    for (let i = sentences.length - 1; i >= 0; i--) {
      const sentence = sentences[i].trim()
      if (this.isUsefulSentence(sentence) && !/^[0-9]+[.)]/.test(sentence)) {
        console.log('ÂëΩ‰∏≠Êú´Â∞æÂè•Â≠ê:', sentence)
        return sentence
      }
    }

    const fallback = reasoningContent.slice(-120).trim()
    console.log('‰ΩøÁî®Â∞æÈÉ®ÂÜÖÂÆπ‰Ωú‰∏∫ÂõûÂ§ç:', fallback)
    return fallback
  }

  async sendMessage(
    messages: GLMMessage[],
    onStream?: (content: string) => void,
    enableWebSearch: boolean = true,
    onSearchResults?: (results: { formattedText: string; structuredResults: SearchResult[] }) => void
  ): Promise<string> {
    try {
      console.log('ÂºÄÂßãË∞ÉÁî® GLM Chat Interface')

      const lastMessage = messages[messages.length - 1]
      const shouldUseWebSearch = lastMessage?.role === 'user' &&
        (enableWebSearch || this.needsWebSearch(lastMessage.content))

      const enhancedMessages = [...messages]

      if (shouldUseWebSearch) {
        console.log('ÂêØÁî®ÁΩëÁªúÊêúÁ¥¢ÂäüËÉΩ')
        if (onStream) {
          onStream('ÔºàÊ≠£Âú®ËÅîÁΩëÊêúÁ¥¢ÊúÄÊñ∞‰ø°ÊÅØÔºåËØ∑Á®çÂÄô...Ôºâ\n')
        }

        try {
          const searchResponse = await this.performWebSearch(lastMessage.content)
          const formattedResults = this.formatWebSearchResults(searchResponse)

          if (formattedResults) {
            const timestamp = new Date().toLocaleString()
            const formattedForUser = `üîé ÁΩëÁªúÊêúÁ¥¢ÁªìÊûúÔºà${timestamp}Ôºâ\n\n${formattedResults.formattedText}`

            if (onSearchResults) {
              onSearchResults({
                formattedText: formattedForUser,
                structuredResults: formattedResults.structuredResults,
              })
            }

            enhancedMessages.push({
              role: 'system',
              content: `‰ª•‰∏ãÊòØÂàöÂàöÈÄöËøáÁΩëÁªúÊêúÁ¥¢Ëé∑ÂèñÁöÑÊúÄÊñ∞‰ø°ÊÅØÔºà${timestamp}ÔºâÔºö\n${formattedResults.formattedText}\nËØ∑ÁªìÂêàËøô‰∫õÂÆûÊó∂Êï∞ÊçÆÂõûÁ≠îÁî®Êà∑ÁöÑÈóÆÈ¢òÔºåÂπ∂Âú®ÂºïÁî®ÊêúÁ¥¢ÂÜÖÂÆπÊó∂Ê≥®ÊòéÊù•Ê∫ê„ÄÇ`,
            })
          } else {
            console.log('ÁΩëÁªúÊêúÁ¥¢Ê≤°ÊúâËøîÂõûÊúâÊïà‰ø°ÊÅØ')
          }
        } catch (searchError) {
          console.error('ÁΩëÁªúÊêúÁ¥¢Â§±Ë¥•:', searchError)
          if (onStream) {
            onStream('ÔºàÁΩëÁªúÊêúÁ¥¢Â§±Ë¥•ÔºåÂ∞ÜÂü∫‰∫éÂ∑≤ÊúâÁü•ËØÜÁªßÁª≠ÂõûÁ≠î„ÄÇÔºâ\n')
          }
        }
      }

      const requestBody: GLMChatRequest = {
        model: 'glm-4.6',
        messages: enhancedMessages,
        stream: true,
        temperature: 0.7,
        max_tokens: 2000,
      }

      console.log('ËØ∑Ê±Ç‰Ωì:', JSON.stringify(requestBody, null, 2))

      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify(requestBody),
      })

      console.log('ÂìçÂ∫îÁä∂ÊÄÅ:', response.status, response.statusText)

      if (!response.ok) {
        const errorText = await response.text()
        console.error('API ÈîôËØØÂìçÂ∫î:', errorText)
        throw new Error(`GLM API Error: ${response.status} ${response.statusText}`)
      }

      const reader = response.body?.getReader()
      const decoder = new TextDecoder()
      let fullContent = ''
      let fullReasoningContent = ''

      if (!reader) {
        throw new Error('No response body reader available')
      }

      let sseBuffer = ''
      let streamCompleted = false

      const processEventBlock = (block: string): boolean => {
        const lines = block.split('\n')

        for (const rawLine of lines) {
          const line = rawLine.trim()
          if (!line || !line.startsWith('data:')) {
            continue
          }

          const data = line.slice(line.indexOf(':') + 1).trim()
          if (!data) {
            continue
          }

          if (data === '[DONE]') {
            console.log('ÊµÅÂºèÂìçÂ∫îÂÆåÊàê')
            return true
          }

          try {
            const parsed = JSON.parse(data) as GLMStreamResponse
            const content = parsed.choices[0]?.delta?.content
            const reasoning = parsed.choices[0]?.delta?.reasoning_content
            const toolCalls = parsed.choices[0]?.delta?.tool_calls

            if (content) {
              fullContent += content
              if (onStream) {
                onStream(fullContent)
              }
            }

            if (reasoning) {
              fullReasoningContent += reasoning
            }

            if (toolCalls && toolCalls.length > 0) {
              console.log('Êî∂Âà∞Â∑•ÂÖ∑Ë∞ÉÁî®:', toolCalls)
            }
          } catch (parseError) {
            console.warn('Ëß£ÊûêÊµÅÊï∞ÊçÆÂ§±Ë¥•:', data, parseError)
          }
        }

        return false
      }

      try {
        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          sseBuffer += decoder.decode(value, { stream: true })
          const eventBlocks = sseBuffer.split('\n\n')
          sseBuffer = eventBlocks.pop() ?? ''

          for (const block of eventBlocks) {
            if (processEventBlock(block)) {
              streamCompleted = true
              break
            }
          }

          if (streamCompleted) {
            break
          }
        }
      } finally {
        reader.releaseLock()
      }

      if (!streamCompleted && sseBuffer.trim()) {
        streamCompleted = processEventBlock(sseBuffer)
      }

      if (!fullContent && fullReasoningContent) {
        const extracted = this.extractReplyFromReasoning(fullReasoningContent)
        if (onStream) {
          onStream(extracted)
        }
        return extracted
      }

      return fullContent
    } catch (error) {
      console.error('GLM API Error:', error)
      throw error
    }
  }

  async validateApiKey(apiKey: string): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: 'glm-4.6',
          messages: [{ role: 'user', content: 'Hello' }],
          max_tokens: 10,
        }),
      })

      return response.ok
    } catch (error) {
      console.error('API Key validation error:', error)
      return false
    }
  }
}
